{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f21a1cbb",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92ea7a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 14:40:28.643918: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "from tqdm import tqdm\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing import text\n",
    "from keras.optimizers import Adam\n",
    "# outdated: from keras.preprocessing import sequence \n",
    "from keras.utils.data_utils import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import squarify\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38483b2d",
   "metadata": {},
   "source": [
    "# Load Final LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07bd5878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-09 14:41:09.996542: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model_lstm = load_model('final_lstm.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134bce03",
   "metadata": {},
   "source": [
    "# Function for cleaning + lemmatizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d45aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "\n",
    "# Define a function to preprocess the tweets\n",
    "def preprocess_tweet(tweet):\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Tokenize the tweet\n",
    "    words = word_tokenize(tweet)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Join words back into a sentence\n",
    "    cleaned_tweet = ' '.join(words)\n",
    "    \n",
    "    return cleaned_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e170fa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you to all of the television viewers tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can you imagine if I had the small crowds that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NATO commander agrees members should pay up vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow, NATO's top commander just announced that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The \"Rust Belt\" was created by politicians lik...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets\n",
       "0  Thank you to all of the television viewers tha...\n",
       "1  Can you imagine if I had the small crowds that...\n",
       "2  NATO commander agrees members should pay up vi...\n",
       "3  Wow, NATO's top commander just announced that ...\n",
       "4  The \"Rust Belt\" was created by politicians lik..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_tweets_df = pd.read_csv('trumptweets.csv', encoding='ISO-8859-1')\n",
    "trump_tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f360cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trump_tweets_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a018f4",
   "metadata": {},
   "source": [
    "# Clean tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a02feea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Trump tweets using preprocess_tweets function\n",
    "trump_tweets_df['cleaned_tweet'] = trump_tweets_df['Tweets'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ffa4f",
   "metadata": {},
   "source": [
    "# Preprocess tweets + Predict MBTI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db4463d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "934/934 [==============================] - 21s 23ms/step\n",
      "Predicted MBTI Type for Trump's Tweets: ENFP\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "labelencoder = joblib.load('labelencoder_lstm.pkl')\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "max_len = 40  # Adjust to match the model's input length\n",
    "X_trump = tokenizer.texts_to_sequences(trump_tweets_df['cleaned_tweet'])\n",
    "X_trump = pad_sequences(X_trump, padding='post', maxlen=max_len)\n",
    "\n",
    "# Make a single prediction for all the tweets using the pre-trained model\n",
    "predictions = loaded_model_lstm.predict(X_trump)\n",
    "\n",
    "# Decode the prediction back to an MBTI type\n",
    "predicted_mbti_enc = np.argmax(predictions, axis=1)  # Get the index of the highest probability\n",
    "predicted_mbti = labelencoder.inverse_transform(predicted_mbti_enc)  # Inverse transform to get the MBTI label\n",
    "\n",
    "# Print the predicted MBTI type\n",
    "print(\"Predicted MBTI Type for Trump's Tweets:\", predicted_mbti[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed675b18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
